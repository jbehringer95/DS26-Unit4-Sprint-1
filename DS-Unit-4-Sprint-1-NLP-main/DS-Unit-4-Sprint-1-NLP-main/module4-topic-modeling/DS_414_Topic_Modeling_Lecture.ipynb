{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cOMBkFKn6uEK"
   },
   "source": [
    "# Topic Modeling (Prepare)\n",
    "\n",
    "On Monday we talked about summarizing your documents using just token counts. Today, we're going to learn about a much more sophisticated approach - learning 'topics' from documents. Topics are a latent structure. They are not directly observable in the data, but we know they're there by reading them.\n",
    "\n",
    "> **latent**: existing but not yet developed or manifest; hidden or concealed.\n",
    "\n",
    "## Use Cases\n",
    "Primary use case: What the are your documents about? Who might want to know that in industry - \n",
    "* Identifying common themes in customer reviews\n",
    "* Grouping job ads into categories \n",
    "* Monitoring communications (Email - State Department, Google) \n",
    "\n",
    "## Learning Objectives\n",
    "*At the end of the lesson you should be able to:*\n",
    "* Part 1: Describe how an LDA Model works\n",
    "* Part 2: Build a LDA Model with Gensim\n",
    "* Part 3: Interpret LDA results & Select the appropriate number of topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rnyNg8sQ6uEL"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from pandarallel import pandarallel\n",
    "\n",
    "\n",
    "import spacy\n",
    "spacy.util.fix_random_seed(0)\n",
    "\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xbZjG6U86uEe"
   },
   "source": [
    "# Part 1: Describe how an LDA Model works\n",
    "\n",
    "We are going to focus on a high level of understand for how LDA works, meaning we are going to focus on \"what it does\" instead of \"how it does it\". I realize that this may be unsatisfying to some so I've included some resources that serve as a prerequisite for understanding how LDA works at a mathematical level. \n",
    "\n",
    "LDA is a [**Probabilistic Graphical Model (PGM)**](https://en.wikipedia.org/wiki/Graphical_model)\n",
    "\n",
    "PGM are represented by a graph that expresses the conditional dependence structure between random variables. Here's the LDA representation dependency graph: \n",
    "\n",
    "![](https://filebox.ece.vt.edu/~s14ece6504/projects/alfadda_topic/main_figure_3.png)\n",
    "\n",
    "These image is communicating the hierarchical dependency between probability distributions and their parameters. This is an application of Bayesian Probability - on steroids. \n",
    "\n",
    "\n",
    "In order to understand how LDA works, one must first understand how PGM work. If this is something that you're interested in learning more about here are some resources: \n",
    "\n",
    "This Github repo that has transformed a textbook in a collection of Jupyter Notebooks. This repo is call [**\"Bayesian Methods for Hackers\"**](https://github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers) The cool thing about this repo is that each chapter has the same material covered in several notebooks but each notebook is written in a different python package: **PyMC2, PyMC3, Pyro, and Tensorflow Probability.** So you can even learn a new library if you want or stick to what you know. \n",
    "\n",
    "Having said that, [**Pyro**](https://pyro.ai/) is considered a very powerful probabilistic programming library that even combines probabilistic programming with deep learning. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resources for LDA\n",
    "\n",
    "[**Your Guide to Latent Dirichlet Allocation**](https://medium.com/@lettier/how-does-lda-work-ill-explain-using-emoji-108abf40fa7d) Here's a medium article that works through an example of LDA. This is useful if you'd like to get an exposure of LDA outside of this notebook.\n",
    "\n",
    "[**LDA Topic Modeling**](https://lettier.com/projects/lda-topic-modeling/)This is an interactive data visualization tool that allows us to explore a simple and visual example of LDA. We'll be using this to learn about LDA in class. \n",
    "\n",
    "[**Topic Modeling with Gensim**](https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/) This is an example of implementing LDA using the same dataset that we are using in the guided project.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "\n",
    "We are going to load some emails. Those emails do belong to topics however those topics are hierarchical.\n",
    "\n",
    "    sci\n",
    "        \\_ electronics, space\n",
    "\n",
    "\n",
    "    talk\n",
    "        \\_politics \n",
    "                  \\_ guns, middle east\n",
    "              \n",
    "So what's the best way to categorize these emails - is it between science and talk? \n",
    "\n",
    "Is it between electronics, space, guns, and the Middle East? \n",
    "\n",
    "The Middle East is a pretty broad topics in and of itself, should that topic be broken down into further sub-topics?\n",
    "\n",
    "\n",
    "Let's learn about Topic Modeling and how it can help us answer this questions!\n",
    "\n",
    "### Load Email Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notice that the categories are hierarchical\n",
    "# so there is a sense in which we 2 topics but also as many as 4 topics  \n",
    "categories = ['sci.electronics', 'sci.space', \n",
    "              'talk.politics.guns', 'talk.politics.mideast']\n",
    "data = fetch_20newsgroups(categories=categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "53a96e4bd0cab21c17f1baa88b5699d8",
     "grade": false,
     "grade_id": "cell-3240b1c818e9dcc2",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# create X and Y from data\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "colab_type": "code",
    "id": "qaMsy1XAGLxc",
    "outputId": "0a981642-93ef-4a95-c6a2-c5ca7c5151e0"
   },
   "outputs": [],
   "source": [
    "# loda data into a dataframe \n",
    "\n",
    "\n",
    "data = {\n",
    "    'content': X,\n",
    "    'target': Y,\n",
    "    'target_names': [target_names[target_id] for target_id in Y]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "deletable": false,
    "id": "na2bkOcFGter",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "839eeeb300650deafafc2dcd19a9e597",
     "grade": false,
     "grade_id": "cell-6ce62b4e40acee5f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "outputId": "6c8d1a19-3719-4e28-d8c6-d3202fdd6257"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean our text data and save it to a new column\n",
    "df[\"clean_data\"] = df[\"content\"].apply(clean_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Tokens \n",
    "\n",
    "Before we can use the Gemsim library to create bag-of-words vectors in exactly the right way that the LDA model wants, we must first create tokens. \n",
    "\n",
    "Let's use spaCy to create some lemmas. But first let's initialize our multi-processing library `pandarallel` which will empower us to use the same dataframe that our data is stored in but be able to create tokens in parallel so as to save time.\n",
    "\n",
    "Here's the documentation for [**pandarallel**](https://github.com/nalepae/pandarallel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we mush initalize pandarallel before we can use it\n",
    "pandarallel.initialize(progress_bar=True, nb_workers=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in our spaCy language model\n",
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6EBPQXqEKE9P"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# create our tokens in the form of lemmas \n",
    "df['lemmas'] = df['clean_data'].parallel_apply(lambda x: [token.lemma_ for token in nlp(x) if (token.is_stop != True) and (token.is_punct != True)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take a look at our lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print out the lemmeas from the first article"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter out low quality lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_lemmas(lemmas):\n",
    "    \"\"\"\n",
    "    Filter out any lemmas that are 2 characters or smaller\n",
    "    \"\"\"\n",
    "    return [lemmas for lemmas in lemmas if len(lemmas) > 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply filter_lemmas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The two main inputs to the LDA topic model are the dictionary (id2word) and the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "id": "1klqRpqtJxWc",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dd66ab4eff9f69a3e9be0aa57fdc2598",
     "grade": false,
     "grade_id": "cell-79d38b90e5c6e38b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Create Dictionary\n",
    "\n",
    "# Term Document Frequency\n",
    "\n",
    "# stores (token id, token count) for each doc in the corpus\n",
    "\n",
    "# Human readable format of corpus (term-frequency)\n",
    "\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Estimate a LDA Model with Gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Train an LDA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fasvjf0VLQ2a"
   },
   "outputs": [],
   "source": [
    "### This cell runs the single-processor version of the model (slower)\n",
    "# %%time\n",
    "# lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "#                                            id2word=id2word,\n",
    "#                                            num_topics=20, \n",
    "#                                            chunksize=100,\n",
    "#                                            passes=10,\n",
    "#                                            per_word_topics=True)\n",
    "# lda_model.save('lda_model.model')\n",
    "# # https://radimrehurek.com/gensim/models/ldamodel.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "num_topics = 2\n",
    "### This cell runs the multi-processor version of the model (faster)\n",
    "lda_multicore_2_topics = gensim.models.ldamulticore.LdaMulticore(corpus=corpus,\n",
    "                                                        id2word=id2word,\n",
    "                                                        num_topics=num_topics, \n",
    "                                                        chunksize=100,\n",
    "                                                        passes=10,# runtime related parameter\n",
    "                                                        per_word_topics=True,\n",
    "                                                        workers=10, # runtime related parameter\n",
    "                                                        random_state=1234, \n",
    "                                                        iterations=20) # runtime related parameter\n",
    "\n",
    "num_topics = 6\n",
    "### This cell runs the multi-processor version of the model (faster)\n",
    "lda_multicore_6_topics = gensim.models.ldamulticore.LdaMulticore(corpus=corpus,\n",
    "                                                        id2word=id2word,\n",
    "                                                        num_topics=num_topics, \n",
    "                                                        chunksize=100,\n",
    "                                                        passes=10,# runtime related parameter\n",
    "                                                        per_word_topics=True,\n",
    "                                                        workers=10, # runtime related parameter\n",
    "                                                        random_state=1234, \n",
    "                                                        iterations=20) # runtime related parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import models\n",
    "#lda_multicore =  models.LdaModel.load('lda_multicore.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Interpret LDA results & Select the appropriate number of topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CYXi480VLaHK"
   },
   "outputs": [],
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim.prepare(lda_multicore_2_topics, corpus, id2word)\n",
    "vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim.prepare(lda_multicore_6_topics, corpus, id2word)\n",
    "vis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is topic coherence?\n",
    "Topic Coherence measures score a single topic by **measuring the degree of semantic similarity between high scoring words in the topic**. These measurements help distinguish between topics that are semantically interpretable topics and topics that are artifacts of statistical inference.\n",
    "\n",
    "\n",
    "A set of statements or facts is said to be coherent, if they support each other. Thus, a coherent fact set can be interpreted in a context that covers all or most of the facts. An example of a coherent fact set is **“the game is a team sport”**, **“the game is played with a ball”**, **“the game demands great physical efforts”**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rjtXk8J3LaXC"
   },
   "outputs": [],
   "source": [
    "def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=3):\n",
    "    \"\"\"\n",
    "    Compute c_v coherence for various number of topics\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    dictionary : Gensim dictionary\n",
    "    corpus : Gensim corpus\n",
    "    texts : List of input texts\n",
    "    limit : Max num of topics\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    model_list : List of LDA topic models\n",
    "    coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n",
    "    \"\"\"\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for num_topics in range(start, limit, step):\n",
    "        model = gensim.models.ldamulticore.LdaMulticore(corpus=corpus,\n",
    "                                                        id2word=id2word,\n",
    "                                                        num_topics=num_topics, \n",
    "                                                        chunksize=100,\n",
    "                                                        passes=10,\n",
    "                                                        random_state=1234,\n",
    "                                                        per_word_topics=True,\n",
    "                                                        workers=10)\n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "\n",
    "    return model_list, coherence_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model_list, coherence_values = compute_coherence_values(dictionary=id2word, corpus=corpus, texts=df['lemmas'], start=2, limit=10, step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start=2; limit=10;  step=1;\n",
    "x = range(start, limit, step)\n",
    "\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.grid()\n",
    "plt.title(\"Coherence Score vs. Number of Topics\")\n",
    "plt.xticks(x)\n",
    "plt.plot(x, coherence_values, \"-o\")\n",
    "\n",
    "plt.xlabel(\"Num Topics\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Index for Model \n",
    "\n",
    "Due to the probabilistic nature of this model, the modeling results can and usually do vary. Despite this, we will select 8 as the number of topics even if this particular model run doesn't show 8 as having the highest coherence score. Also, even if it doesn't, we  need to ask ourselves how many topics we actually want for our corpus. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_trained_model = model_list[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_trained_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the 3 topics \n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim.prepare(lda_trained_model, corpus, id2word)\n",
    "vis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Topic id/name dictionary \n",
    "\n",
    "When populating your topic id/name dictionary, use the index ordering as shown in the viz tool. \n",
    "\n",
    "We'll use a function to map the the viz tool index ordering with the train LDA model ordering. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f578664ea9e81e93977a50dee417f2df",
     "grade": false,
     "grade_id": "cell-777be73d0d1455f0",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# keys - use topic ids from pyLDAvis visualization \n",
    "# values - topic names that you create \n",
    "# save dictionary to `vis_topic_name_dict`\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_id_lookup_dict(vis, vis_topic_name_dict):\n",
    "    \"\"\"\n",
    "    Both the starting index and the ordering of topic ids bewteen the trained LDA model \n",
    "    and the viz tool are different. So we need to create a look up dictionary that maps \n",
    "    the correct association between topic ids from both sources. \n",
    "    \"\"\"\n",
    "    # value is order of topic ids accoridng to pyLDAvis tool \n",
    "    # key is order of topic ids according to lda model\n",
    "    model_vis_tool_topic_id_lookup = vis.topic_coordinates.topics.to_dict()\n",
    "\n",
    "    # invert dictionary so that \n",
    "    # key is order of topic ids accoridng to pyLDAvis tool \n",
    "    # value is order of topic ids according to lda model\n",
    "    topic_id_lookup =  {v:k for k, v in model_vis_tool_topic_id_lookup.items()}\n",
    "    \n",
    "    # iterate through topic_id_lookup and index vis_topic_name_dict using the keys \n",
    "    # in order to swap the viz topic ids in vis_topic_name_dict for the lda model topic ids \n",
    "    return {v:vis_topic_name_dict[k]  for k, v in topic_id_lookup.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "92d9c30261d1cdb278e73f457c166609",
     "grade": false,
     "grade_id": "cell-0718245fd125b36e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_name_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assign Each Document a Topic Name\n",
    "\n",
    "Now that we have a topic id/name look up dict that is aligned with the index ordering of the trained LDA model, we can move forward to giving each topic a topic name. \n",
    "\n",
    "The function below has been given to you. However, you highly encouraged to read through it and make sure that you understand what it is doing each step of the way. In fact, a good way to do this is to copy and paste the code inside of the function into a new cell, comment out all the lines of code and line by line, uncomment the code and see the output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_ids_for_docs(lda_model, corpus):\n",
    "    \n",
    "    \"\"\"\n",
    "    Passes a Bag-of-Words vector into a trained LDA model in order to get the topic id of that document. \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    lda_model: Gensim object\n",
    "        Must be a trained model \n",
    "        \n",
    "    corpus: nested lists of tuples, \n",
    "        i.e. [[(),(), ..., ()], [(),(), ..., ()], ..., [(),(), ..., ()]]\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    topic_id_list: list\n",
    "        Contains topic ids for all document vectors in corpus \n",
    "    \"\"\"\n",
    "    \n",
    "    # store topic ids for each document\n",
    "    doc_topic_ids = []\n",
    "\n",
    "    # iterature through the bow vectors for each doc\n",
    "    for doc_bow in corpus:\n",
    "        \n",
    "        # store the topic ids for the doc\n",
    "        topic_ids = []\n",
    "        # store the topic probabilities for the doc\n",
    "        topic_probs = []\n",
    "\n",
    "        # list of tuples\n",
    "        # each tuple has a topic id and the prob that the doc belongs to that topic \n",
    "        topic_id_prob_tuples = lda_trained_model.get_document_topics(doc_bow)\n",
    "        \n",
    "        # iterate through the topic id/prob pairs \n",
    "        for topic_id_prob in topic_id_prob_tuples:\n",
    "            \n",
    "            # index for topic id\n",
    "            topic_id = topic_id_prob[0]\n",
    "            # index for prob that doc belongs that the corresponding topic\n",
    "            topic_prob = topic_id_prob[1]\n",
    "\n",
    "            # store all topic ids for doc\n",
    "            topic_ids.append(topic_id)\n",
    "            # store all topic probs for doc\n",
    "            topic_probs.append(topic_prob)\n",
    "\n",
    "        # get index for largest prob score\n",
    "        max_topic_prob_ind = np.argmax(topic_probs)\n",
    "        # get corresponding topic id\n",
    "        max_prob_topic_id = topic_ids[max_topic_prob_ind]\n",
    "        # store topic id that had the highest prob for doc being a memebr of that topic\n",
    "        doc_topic_ids.append(max_prob_topic_id)\n",
    "        \n",
    "    return doc_topic_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the topic id for each doc in the corpus \n",
    "topic_id_list = get_topic_ids_for_docs(lda_trained_model, corpus)\n",
    "\n",
    "# creat a feature for document's topic id\n",
    "df[\"topic_id\"] = topic_id_list\n",
    "\n",
    "# iterate through the topic id and use the lookup table to assign each document with a topic name\n",
    "df[\"new_topic_name\"] = df[\"topic_id\"].apply(lambda topic_id: topic_name_dict[topic_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cool! so now all of our documents have topic ids and names \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can mask for all Space articles \n",
    "science_mask = df.topic_id == 3\n",
    "df[science_mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## Where do we go from here?\n",
    "\n",
    "What exactly did we just accomplish?\n",
    "\n",
    "Outside of this guided project (i.e. in your job) you may or may not have access to existing article topic names like we did with this data set. Meaning that we won't always have a point of reference to \"check our answers\". So let's explore 2 possible situations in which you might find yourself using this Unsupervised Learning Topic Model. \n",
    "\n",
    "### 1. You have access to existing document topic labels\n",
    "\n",
    "In this case, why would we bother with Topic Modeling? It could be the case that the current topic labels are actually not helpful for whatever task you're working on. For instance, our email dataset here has topic names however those topic labels are hierarchical, which doesn't suit your needs for some reason. So one option is generate new labels that do suit your needs (like we did here). \n",
    "\n",
    "### 2. Your corpus doesn't have any document topic labels\n",
    "\n",
    "In this case, you don't have any pre-existing topic labels. Maybe you work at Indeed or LinkedIn or Google and your job is to bring some structure to a huge collection of emails and messages that aren't labeled in any meaningful way and so it's difficult to just sort through these documents. This is a perfect use case of Topic Modeling. After you apply topic modeling, you'll then have organized your emails into broad categories and you can start structuring and then analyze your corpus, and maybe even build a supervised learning model to predict the topic of the document!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "REFERENCE_LS_DS_414_Topic_Modeling.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "py37  (Python3)",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

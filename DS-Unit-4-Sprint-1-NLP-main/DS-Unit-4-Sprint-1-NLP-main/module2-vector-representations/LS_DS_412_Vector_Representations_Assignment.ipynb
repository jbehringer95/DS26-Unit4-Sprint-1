{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "\n",
    "# Vector Representations\n",
    "## *Data Science Unit 4 Sprint 2 Assignment 2*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 159
    },
    "colab_type": "code",
    "id": "hyj-f9FDcVFp",
    "outputId": "5dd045fe-6e4c-458c-e2fc-253c3da9c805"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = 1500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M7bcmqfGXrFG"
   },
   "source": [
    "## 1) *Clean:* Job Listings from indeed.com that contain the title \"Data Scientist\" \n",
    "\n",
    "You have `job_listings.csv` in the data folder for this module. The text data in the description column is still messy - full of html tags. Use the [BeautifulSoup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/) library to clean up this column. You will need to read through the documentation to accomplish this task. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KcYlc1URXhlC"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Unnamed: 0  \\\n",
       "0           0   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         description  \\\n",
       "0  b\"<div><div>Job Requirements:</div><ul><li><p>\\nConceptual understanding in Machine Learning models like Nai\\xc2\\xa8ve Bayes, K-Means, SVM, Apriori, Linear/ Logistic Regression, Neural, Random Forests, Decision Trees, K-NN along with hands-on experience in at least 2 of them</p>\\n</li><li><p>Intermediate to expert level coding skills in Python/R. (Ability to write functions, clean and efficient data manipulation are mandatory for this role)</p>\\n</li><li><p>Exposure to packages like NumPy, SciPy, Pandas, Matplotlib etc in Python or GGPlot2, dplyr, tidyR in R</p>\\n</li><li><p>Ability to communicate Model findings to both Technical and Non-Technical stake holders</p>\\n</li><li><p>Hands on experience in SQL/Hive or similar programming language</p>\\n</li><li><p>Must show past work via GitHub, Kaggle or any other published article</p>\\n</li><li><p>Master's degree in Statistics/Mathematics/Computer Science or any other quant specific field.</p></li></ul><div><div><div><div><div><div>\\nApply Now</div></div></div></div></div></div></div><div></div>\"   \n",
       "\n",
       "             title  \n",
       "0  Data scientistÂ   "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>description</th>\n      <th>title</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>b\"&lt;div&gt;&lt;div&gt;Job Requirements:&lt;/div&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;\\nConceptual understanding in Machine Learning models like Nai\\xc2\\xa8ve Bayes, K-Means, SVM, Apriori, Linear/ Logistic Regression, Neural, Random Forests, Decision Trees, K-NN along with hands-on experience in at least 2 of them&lt;/p&gt;\\n&lt;/li&gt;&lt;li&gt;&lt;p&gt;Intermediate to expert level coding skills in Python/R. (Ability to write functions, clean and efficient data manipulation are mandatory for this role)&lt;/p&gt;\\n&lt;/li&gt;&lt;li&gt;&lt;p&gt;Exposure to packages like NumPy, SciPy, Pandas, Matplotlib etc in Python or GGPlot2, dplyr, tidyR in R&lt;/p&gt;\\n&lt;/li&gt;&lt;li&gt;&lt;p&gt;Ability to communicate Model findings to both Technical and Non-Technical stake holders&lt;/p&gt;\\n&lt;/li&gt;&lt;li&gt;&lt;p&gt;Hands on experience in SQL/Hive or similar programming language&lt;/p&gt;\\n&lt;/li&gt;&lt;li&gt;&lt;p&gt;Must show past work via GitHub, Kaggle or any other published article&lt;/p&gt;\\n&lt;/li&gt;&lt;li&gt;&lt;p&gt;Master's degree in Statistics/Mathematics/Computer Science or any other quant specific field.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;div&gt;&lt;div&gt;&lt;div&gt;&lt;div&gt;&lt;div&gt;&lt;div&gt;\\nApply Now&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;/div&gt;\"</td>\n      <td>Data scientist</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "##### Your Code Here #####\n",
    "df = pd.read_csv('./data/job_listings.csv')\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_description = []\n",
    "\n",
    "for text in df['description']:\n",
    "    soup = BeautifulSoup(text, 'html.parser')\n",
    "    clean_description.append(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "br/><br/>\\n<ul>\\n<li>Delivering a better understanding of why a traveler books a hotel or flight, and utilizing those insights in production models which are used to improve ad relevance, timeliness, and performance for millions of ads per day</li>\\n<li>Analyzing, visualizing, and improving our ML pipeline that pushes thousands of models into production each month</li>\\n<li>Applying ideas from game theory to better understand the value of our audience targeting methods</li>\\n<li>Optimizing automated campaign management which allocates budget for over 40 million display ad impressions daily for over a thousand customers and millions of ad spend per year</li>\\n</ul>\\nAs a part of engineering, we also drive our solutions to production including:\\n<br/><br/>\\n<ul>\\n<li>Creating data processing jobs using Google's big data infrastructure such as BigQuery</li>\\n<li>Deploying our codebase to production with docker/containers on Google Cloud's Kubernetes platform</li>\\n<li>Building and improving internal data science tools like our Jupyter server to scale our impact</li>\\n</ul>\\n<b>The Role:</b><br/>\\n<b>Day-to-day responsibilities include:</b><br/>\\n<ul>\\n<li>Collaborating with the team to discover new insights in our unique traveler profile data, and utilizing those insights to improve conversion models</li>\\n<li>Adding new features to our automated campaign management systems and our A/B testing platform</li>\\n<li>Mentoring more junior data science engineers by reviewing their code, helping them debug, and supporting their growth</li>\\n<li>Representing the team and its capabilities across the business</li>\\n<li>Contributing to our production code base, driving additional efficiency and impacting Sojern's bottomline</li>\\n</ul>\\n<b>Requirements:</b><br/>\\n<ul>\\n<li>Python Proficiency -- It\\xe2\\x80\\x99s our lingua franca, and we\\xe2\\x80\\x99re big Jupyter fans</li>\\n<li>MS or PhD in CS or STEM -- Ability to transform concepts into practical solutions</li>\\n<li>Production Machine Learning Experience -- Successful implementation of ML solutions in production setting</li>\\n<li>Communication Ability -- Experience/comfort in presenting abstract concepts</li>\\n<li>Experience as a Data Scientist -- 4+ years of experience with data science/ML</li>\\n<li>Ad Tech Experience -- 1+ years of experience with data science/ML techniques as applied to Ad Tech, specifically experience on FB, RTB, SEM, cross-channel attribution, cross-device graph technologies</li>\\n</ul>\\n<b>Company Culture:</b><br/>\\nAt Sojern, culture is king. We keep the stress low, the dress casual, and the work interesting. No one is counting your vacation days, we trust (and encourage!) our employees to take the time they need. We regularly eat out as a team, provide the hardware you\\xe2\\x80\\x99ll need, and otherwise let you dig in!\\n<br/><br/>\\nRecognized on the Top Company Cultures list by Entrepreneur Magazine, Sojern is headquartered in San Francisco, with teams based in Dubai, Dublin, Hong Kong, London, Mexico City, New York, Omaha, Paris, Singapore, and Sydney. For more information, visit www.sojern.com.\\n<br/><br/>\\n<b>Perks:</b><br/>\\n<ul>\\n<li>Opportunities: Be part of a growing team with training and support to help you grow</li>\\n<li>Ownership: Lead creative and challenging projects</li>\\n<li>Give Back: We give 40 hours a year to volunteer and organize office volunteer programs with local organizations</li>\\n<li>Culture: Strong core business values, focus on teamwork, vibrant, social and fun environment</li>\\n<li>Snacks: Variety of snacks in the office</li>\\n<li>Meals: Monthly catered lunches &amp; happy hours</li>\\n<li>Wealth: Stock options</li>\\n<li>Time Off: Flexible vacation days</li>\\n</ul>\\nAt Sojern, we value diversity and always treat all employees and job applicants based on merit, qualifications, competence, and talent. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.\",\n",
       " b'<div class=\"jobsearch-JobMetadataHeader icl-u-xs-mb--md\"><div class=\"jobsearch-JobMetadataHeader-item icl-u-xs-mt--xs\">Internship</div></div><div><div>At Uber, we ignite opportunity by setting the world in motion. We take on big problems to help drivers, riders, delivery partners, and eaters get moving in more than 600 cities around the world.</div><div></div><br/>\\n<div>\\nWe welcome people from all backgrounds who seek the opportunity to help build a future where everyone and everything can move independently. If you have the curiosity, passion, and collaborative spirit, work with us, and let\\xe2\\x80\\x99s move the world forward, together.</div>\\n<div><b>About the Role</b></div><div></div><br/>\\n<div>\\nWe are looking for a PhD intern candidates to join the Forecasting and Anomaly Detection Platform team for the Summer of 2019 (3 months). During that time the intern will develop new methods that address our complex problem space working closing with a team of experienced Data Scientists and domain experts.</div><div></div><br/>\\n<div><b>\\nWhat You\\'ll Do</b></div><div></div><br/>\\n<ul><li>\\nPush the envelope on what can be done in the realm of time series and anomaly detection, by actively researching and developing the next generation algorithms. Implement these methodologies in a rapidly growing platform designed for broad adoption and ease of use.</li><li>\\nPartner with experienced scientists and engineers in building first-class products</li></ul><div></div><br/>\\n<div><b>\\nSample Projects</b></div><ul><li>\\nhttps://eng.uber.com/m4-forecasting-competition/</li><li>\\nhttps://eng.uber.com/omphalos/</li><li>\\nhttps://eng.uber.com/neural-networks-uncertainty-estimation/</li><li>\\nhttps://eng.uber.com/neural-networks/</li><li>\\nhttps://eng.uber.com/forecasting-introduction/</li></ul><div></div><br/>\\n<div><b>\\nWhat You\\'ll Need</b></div><div></div><br/>\\n<ul><li>\\nPhD candidacy (anticipated graduation in 2020) majoring in Data Science, Statistics, Machine Learning, Physics, Computer Science or other quantitative disciplines</li><li>\\nStrong knowledge of statistical principles and machine learning methods.</li><li>\\nA curious mind</li><li>\\nProficiency in writing good quality code</li></ul><div></div><br/>\\n<div><b>\\nAbout the Team</b></div><div></div><br/>\\n<div>\\nTime Series analysis is central to Uber for a variety of reasons:</div><ul><li>\\naccurate forecasts are essential for informed decision making</li><li>\\nprompt detection of anomalies ensures reliability</li><li>\\nshort-term automated forecasting powers optimization</li></ul><div></div><br/>\\n<div>\\nTo accomplish these goals, the Forecasting and Anomaly Detection Platform develops state-of-the-art Machine Learning techniques and deploys them as scalable tools. Active areas of research include Hierarchical Forecasting, Deep Learning, Bayesian Forecasting, Probabilistic Programming, as well as developing novel statistical models. Our work helps to create technology that ensures the Uber experience is always excellent.</div><div></div><br/>\\n<div>\\nBe sure to check out the Uber Engineering Blog to learn more about the team.</div></div>',\n",
       " b'<div class=\"jobsearch-JobMetadataHeader icl-u-xs-mb--md\"><div class=\"jobsearch-JobMetadataHeader-item\"><span class=\"icl-u-xs-mr--xs\">$200,000 - $350,000 a year</span></div></div><div><div><div>A million people a year die in car collisions around the world and we want that number to be zero. We invite you to help us build an InsurTech company that uses rich customer insights, advanced technology and data science to save lives by preventing car collisions before they happen. To this end, we recently helped launch our first product, hiroad.com, a cloud native insurance solution that rewards people for the act of driving well.</div><div>\\n</div><div>\\nWith impressive funding, a compelling vision, and a world-class team, we\\'re poised to re-engineer a trillion-dollar category from the ground up- and that\\'s just where we\\'re beginning. Longer term, we\\'re out to change behavior and promote mindful living at a societal level.</div><div><br/>\\n</div><div>\\nWe\\'re seeking someone to build and support critical backend systems and services that are core to our business. This includes the rewards system that will be used to increase driver safety, designing APIs, creating/managing databases, and writing automated test suites.</div><div><br/>\\n</div><div>\\nGeneral tools you build will be open sourced and will ideally be consumed by the greater community.</div></div>\\n<div><div><h3 class=\"jobSectionHeader\"><b>Job requirements</b></h3><div><ul><li>\\nThis role will require the candidate to be extremely hands on with building models and data driven tools. Past experience implementing complex data-driven solutions is required.</li><li>\\nAdvanced Python skills. Should be familiar with Python\\xe2\\x80\\x99s scientific computing ecosystem.</li><li>\\nAdvanced SAS skills. Should be familiar with SAS best practices.</li><li>\\nDeep experience with GLMs as well as modern machine learning methods.</li><li>\\nActuarial science is a plus, but is not required.</li></ul></div></div></div>\\n<div><div><h3 class=\"jobSectionHeader\"><b>More details</b></h3><div><ul><li>\\nSalary: We invest in first-rate people and pay top-of-market salaries for most positions, factoring in experience and talent. We are unable to offer equity.</li><li>\\nBenefits: Full medical, dental, vision coverage, 401k, daily catered lunch, wellness reimbursement &amp; on-site shower, four weeks of vacation, six weeks of parental leave, panoramic views, and more.\\n</li><li>Location: Near Montgomery Street BART station, San Francisco, California. Locals preferred, but relocation within the US considered for outstanding candidates.</li></ul></div></div></div>\\n<div><div><i>All are welcome at Blue Owl. We are an equal opportunity and affirmative action employer who values diversity and inclusion and looks for applicants who understand, embrace and thrive in a multicultural world. We do not discriminate on the basis of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.</i></div></div></div>',\n",
       " b\"<p></p><div><p>SENIOR DATA SCIENTIST</p><p>\\nJOB DESCRIPTION</p><p></p><br/>\\n<div><b>\\nABOUT US</b></div><p></p><br/>\\n<div>\\nAmplion synthesizes the world\\xe2\\x80\\x99s biomedical knowledge to accelerate Precision Medicine and enable confident strategic decisioning in drug and diagnostic development. The company's SaaS platform leverages machine learning to provide actionable intelligence across millions of disparate data sources, delivering the leading solution for pre-clinical and clinical evidence in the Life Sciences industry.</div><p></p><br/>\\n<div>\\nAll of us at Amplion are extremely passionate about enabling the life science industry to deliver on the promise of precision medicine. No disruption of a major industry happens with an individual. It takes a great team, aligned around something meaningful and big. If you share in our passion and want to work for a growing company with the opportunity for professional growth with purpose, we\\xe2\\x80\\x99d love to meet you.</div><p></p><br/>\\n<div><b>\\nTHE ROLE</b></div><p></p><br/>\\n<div>\\nWe are looking for a Data Scientist who will support our effort to accelerate the realization of precision medicine. You will be working with our Data Science team to analyze data from a variety of sources of structured and unstructured data to provide insights to our Life Science customers in their efforts to bring precision medicine to consumers.</div><p></p><br/>\\n<div>\\nThe ideal candidate has a strong background in Machine Learning, Natural Language Processing, Python. A Bioscience background is highly preferred.</div><p></p><br/>\\n<ul><li><div>\\nApply machine learning techniques in a statistically rigorous manner</div></li><li><div>\\nWork closely with product team to prioritize data science efforts</div></li><li><div>\\nWork with data engineers to architect data and modeling pipelines</div></li><li><div>\\nPlan, and be able to conduct as needed, end-to-end analyses, from data requirement gathering to data processing and modeling</div></li><li><div>\\nOwn ongoing deliverables and communications</div></li></ul><p></p><br/>\\n<p><b>\\nROLE REQUIREMENTS</b></p><ul><li><p>\\nMS degree in a quantitative discipline (e.g., statistics, physics, applied mathematics, computer science) or equivalent experience.</p></li><li><div>\\n3-5 years experience in applied statistical analysis, machine learning, and data mining</div></li><li><div>\\nExcellent programming skills in Python</div></li><li><div>\\nExperience with SQL and graph databases</div></li><li><div>\\nExperience and knowledge of Python data science ecosystem: pandas, Jupyter, numpy, matplotlib, seaborn</div></li><li><div>\\nExperience and knowledge of at least one Python machine learning framework: e.g., scikit-learn, Keras, TensorFlow, PyTorch</div></li><li><div>\\nExperience running reproducible experiments and analyzing the results using a full end-to-end pipeline: from collecting raw data and preprocessing, statistical modeling and performance benchmarking, to final prototype packaging</div></li><li><div>\\nWillingness to learn new software and platforms as needed</div></li><li><div>\\nSelf-starter able to work in a fast-moving and rapidly evolving environment</div></li><li><div>\\nTeam oriented individual willing to collaborate with multiple colleagues and partners</div></li></ul><div></div><br/>\\n<p><b>\\nPREFERRED QUALIFICATIONS</b></p><ul><li><div>\\nPhD in a quantitative discipline</div></li><li><div>\\nBackground in NLP or bioinformatics</div></li><li><div>\\nExperience in applied NLP and text mining: e.g., named entity recognition, entity linking, document classification, coreference resolution, topic modeling</div></li><li><div>\\nExperience with Python NLP libraries (eg. NLTK, spaCy, AllenNLP)</div></li><li><div>\\nExperience of applying neural net frameworks (e.g., Keras, Tensorflow, PyTorch), to NLP modeling</div></li></ul><p></p><br/>\\n<p><b>\\nADDITIONAL INFORMATION</b></p><p></p><p>\\nAmplion is an equal opportunity employer and prohibits discrimination and harassment of any kind. At Amplion, we value diversity. All aspects of employment will be based on merit, competence, performance, and business needs. We do not discriminate on the basis of race, color, religion, marital status, age, national origin, ancestry, physical or mental disabilities, medical condition, pregnancy, genetic information, gender, sexual orientation, gender identity or expression, veteran status, or any other status protected under federal, state and local law.</p></div><div></div>\",\n",
       " b'<div></div><div><div><div><div><p>Cerner Intelligence is a new, innovative organization within Cerner focusing on creating contextual, intelligent experiences by leveraging the power of data to discover new evidence-based insights and workflow interventions that drive client value and help achieve the quadruple aim in healthcare. We seek the best and brightest talent to join the team \\xe2\\x80\\x93 individuals who thrive on analytical problem solving and data-driven analysis who are smart, ambitious, and inquisitive.<br/>\\n<br/>\\nAs a Data Scientist, you will discover and develop mathematical models to improve clinical, financial, or operational outcomes at an individual, facility, or population level using advanced mathematical, computational, and machine learning techniques. A few of the responsibilities include supporting feasibility studies, applying modern data storage techniques, discovering explanatory features in high-dimensionality collections of data, exploring data using scientifically valid techniques to applying a modern software or analytic development lifecycle methodology.</p><br/>\\n</div></div></div><p></p><div><div><div><div><div><div><p>\\n</p></div></div></div><h2 class=\"jobSectionHeader\"><b>Client Services</b></h2>\\n<p>Working directly with our clients is one of the most impactful careers you will find. Whether your background is in health care, business or technology you can help transform the quality of care for all of us.</p>\\n</div><div><h2 class=\"jobSectionHeader\"><b>Qualifications</b></h2>\\n<b>Basic Qualifications</b><ul><li>\\nMaster\\xe2\\x80\\x99s Degree in Statistics, Computer Science, Analytics, Biostatistics, Applied Mathematics, Software Engineering, or equivalent relevant work experience.</li><li>\\nAt least 3 years of data mining, quantitative analysis, and/or statistical modeling including predictive performance and algorithm optimization work experience</li><li>\\nExperience working with data mining algorithms including decision trees, probability networks, association rules, clustering, and neural networks</li><li>\\nExperience programming in multiple languages (ideally Python and/or R)</li><li>\\nExperience with MapReduce programming (Hadoop)</li><li>\\nExperience with data warehousing and business intelligence systems, cluster and grid computing</li></ul><b>\\nPreferred Qualifications</b><ul><li>\\nPh.D. in Statistics, Computer Science, Analytics, Biostatistics, Applied Mathematics, Software Engineering, or equivalent relevant work experience</li><li>\\nAt least 3 years of machine learning methods and the principals of visually encoding data work experience</li><li>\\nExperience with relational databases and SQL; NoSQL databases (hBase, Cassandra, MongoDB, Couch DB, Riak) and unstructured data; Spark; Pig and Avro</li><li>\\nExperience with agile software development methodologies</li></ul><b>\\nExpectations</b><ul><li>\\nMust be currently residing in or willing to relocate to the Malvern, PA metro area\\n</li><li>Willing to work additional or irregular hours as needed and allowed by local regulations</li><li>\\nWork in accordance with corporate and organizational security policies and procedures, understand personal role in safeguarding corporate and client assets, and take appropriate action to prevent and report any compromises of security within scope of position</li></ul>\\n</div><div><h2 class=\"jobSectionHeader\"><b>Additional Information</b></h2>\\n<p>Applicants for U.S. based positions with Cerner Corporation must be legally authorized to work in the United States. Verification of employment eligibility will be required at the time of hire. Visa sponsorship may be available for this position.<br/>\\n<br/>\\nSome Cerner positions may be obligated to comply with client-facing requirements and occupational health requests, including but not limited to, an immunization set, an annual flu shot, an annual TB screen, an updated background check, and/or an updated drug screen.</p>\\n<h5 class=\"jobSectionHeader\"><b>Relocation Assistance Available for this Job:</b></h5>\\n<p>Yes - Domestic/Regional</p>\\n<h5 class=\"jobSectionHeader\"><b>Virtual Eligible Job</b></h5>\\n<p>No</p>\\n</div><div><p>Cerner is a place where people are encouraged to innovate with confidence and focus on what is important \\xe2\\x80\\x93 people\\xe2\\x80\\x99s health and the care they receive. We are transforming health care by developing tools and technologies that make it more efficient for care providers and patients to navigate the complexity of our health. From single offices to entire countries, Cerner solutions are licensed at more than 25,000 facilities in over 35 countries.<br/>\\n<br/>\\nCerner\\xe2\\x80\\x99s policy is to provide equal opportunity to all people without regard to race, color, religion, national origin, ancestry, marital status, veteran status, age, disability, pregnancy, genetic information, citizenship status, sex, sexual orientation, gender identity or any other legally protected category. Cerner is proud to be a drug-free workplace.</p></div></div></div></div><div></div>']"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "clean_description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5C4xFZNtX1m2"
   },
   "source": [
    "## 2) Use Spacy to tokenize the listings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dhUHuMr-X-II"
   },
   "outputs": [],
   "source": [
    "##### Your Code Here #####\n",
    "raise Exception(\"\\nThis task is not complete. \\nReplace this line with your code for the task.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-lgCZNL_YycP"
   },
   "source": [
    "## 3) Use Scikit-Learn's CountVectorizer to get word counts for each listing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X2PZ8Pj_YxcF"
   },
   "outputs": [],
   "source": [
    "##### Your Code Here #####\n",
    "raise Exception(\"\\nThis task is not complete. \\nReplace this line with your code for the task.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Zo1iH_UeY7_n"
   },
   "source": [
    "## 4) Visualize the most common word counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M5LB00uyZKV5"
   },
   "outputs": [],
   "source": [
    "##### Your Code Here #####\n",
    "raise Exception(\"\\nThis task is not complete. \\nReplace this line with your code for the task.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bwFsTqrVZMYi"
   },
   "source": [
    "## 5) Use Scikit-Learn's tfidfVectorizer to get a TF-IDF feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-gx2gZCbl5Np"
   },
   "outputs": [],
   "source": [
    "##### Your Code Here #####\n",
    "raise Exception(\"\\nThis task is not complete. \\nReplace this line with your code for the task.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Create a NearestNeighbor Model. Write the description of your ideal datascience job and query your job listings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "##### Your Code Here #####\n",
    "raise Exception(\"\\nThis task is not complete. \\nReplace this line with your code for the task.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FiDfTWceoRkH"
   },
   "source": [
    "## Stretch Goals\n",
    "\n",
    " - Try different visualizations for words and frequencies - what story do you want to tell with the data?\n",
    " - Scrape Job Listings for the job title \"Data Analyst\". How do these differ from Data Scientist Job Listings\n",
    " - Try and identify requirements for experience specific technologies that are asked for in the job listings. How are those distributed among the job listings?\n",
    " - Use a clustering algorithm to cluster documents by their most important terms. Do the clusters reveal any common themes?\n",
    "  - **Hint:** K-means might not be the best algorithm for this. Do a little bit of research to see what might be good for this. Also, remember that algorithms that depend on Euclidean distance break down with high dimensional data.\n",
    " - Create a labeled dataset - which jobs will you apply for? Train a model to select the jobs you are most likely to apply for. :) "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LS_DS_422_BOW_Assignment.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "name": "python370jvsc74a57bd0d9d4c4d46cd2df6cd3e29f938c44eab26042d9bb144eda5c9f4cbd5e9634f1c8",
   "display_name": "Python 3.7.0 64-bit ('U4-S1-NLP': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "nteract": {
   "version": "0.14.3"
  },
  "metadata": {
   "interpreter": {
    "hash": "df67e98752399f1df19cca3c6bce828e5600fc8fe66d1d5fce4520b14f4d0349"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}